name: Lint

on:
  push:
    branches:
    - master
  pull_request:
  workflow_dispatch:

jobs:
  quick-checks:
    runs-on: ubuntu-20.04
    steps:        
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.x
          architecture: x64
      - name: Checkout PyTorch
        uses: actions/checkout@v1
      - name: Ensure consistent CircleCI YAML config
        run: |
          pip install -r requirements.txt
          cd .circleci && ./ensure-consistency.py
      - name: Shellcheck Jenkins scripts
        # https://github.com/koalaman/shellcheck#installing-a-pre-compiled-binary
        run: |
          scversion="stable"
          wget -qO- "https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz" | tar -xJv
          sudo cp "shellcheck-${scversion}/shellcheck" /usr/bin/
          rm -r "shellcheck-${scversion}"
          shellcheck --version
          .jenkins/run-shellcheck.sh
      - name: Ensure no tabs
        run: |
          (! git grep -I -l $'\t' -- . ':(exclude)*.svg' ':(exclude)**Makefile' ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude).gitattributes' ':(exclude).gitmodules' || (echo "The above files have tabs; please convert them to spaces"; false))
      - name: Ensure canonical include
        run: |
          (! git grep -I -l $'#include "' -- ./c10 ./aten ./torch/csrc ':(exclude)aten/src/ATen/native/quantized/cpu/qnnpack/**' || (echo "The above files have include with quotes; please convert them to #include <xxxx>"; false))
      # note that this next step depends on a clean shallow checkout;
      # if you run it locally in a deep checkout then it will complain
      # about android/libs/fbjni/gradlew (in a submodule),
      # as well as all the generated files in torch/test
      - name: Ensure C++ source files are not executable
        run: |
          (! find . \( -path ./third_party -o -path ./.git -o -path ./torch/bin -o -path ./build \) -prune -o -type f -executable -regextype posix-egrep -not -regex '.+(\.(bash|sh|py|so)|git-pre-commit|git-clang-format)$' -print | grep . || (echo 'The above files have executable permission; please remove their executable permission by using `chmod -x`'; false))
      - name: C++ docs check
        run: |
          sudo apt-get install -y doxygen && pip install -r requirements.txt
          cd docs/cpp/source && ./check-doxygen.sh
      - name: CUDA kernel launch check
        run: |
          set -eux
          python torch/testing/check_kernel_launches.py |& tee ${GITHUB_WORKSPACE}/cuda_kernel_launch_checks.txt
    
  flake8-py3:
    runs-on: ${{ matrix.runner_type }}
    strategy:
      matrix:
        runner_type: [ds2v2,ds2v3,ds3v2,ds4v2,ds5v2,f32s,f64s,m5large,n2s2,ubuntu-20.04]
    env:
      #### For stat collection
      runId: ${{ matrix.runner_type }}-${{ github.workflow }}
      artifactsDir: artifacts/${{ github.repository }}
      iostatFile: artifacts/${{ github.repository }}/${{ matrix.runner_type }}-iostat.txt
      vmstatFile: artifacts/${{ github.repository }}/${{ matrix.runner_type }}-vmstat.txt
      timingFile: artifacts/${{ github.repository }}/${{ matrix.runner_type }}-timing.txt
      ##########################
    
    steps:
      #### Start stat collection
      - run: mkdir -p ${{ runner.temp }}/${{ env.artifactsDir }}
      - run: iostat -yxmt 1 > ${{ runner.temp }}/${{ env.iostatFile }} &
      - run: vmstat -n 1 > ${{ runner.temp }}/${{ env.vmstatFile }} &
      - run: date -R > ${{ runner.temp }}/${{ env.timingFile }}
      ##########################

      - name: Setup Python
        uses: actions/setup-python@v1
        with:
          python-version: 3.x
          architecture: x64
      - name: Fetch PyTorch
        uses: actions/checkout@v1
      - name: Checkout PR tip
        run: |
          set -eux
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            # We are on a PR, so actions/checkout leaves us on a merge commit.
            # Check out the actual tip of the branch.
            git checkout ${{ github.event.pull_request.head.sha }}
          fi
          echo ::set-output name=commit_sha::$(git rev-parse HEAD)
        id: get_pr_tip
      - name: Run flake8
        run: |
          set -eux
          pip install flake8==3.8.2 flake8-bugbear flake8-comprehensions flake8-executable flake8-pyi==20.5.0 mccabe pycodestyle==2.6.0 pyflakes==2.2.0
          flake8 --version
          flake8 | tee ${GITHUB_WORKSPACE}/flake8-output.txt
      - name: Add annotations
        uses: pytorch/add-annotations-github-action@master
        with:
          check_name: 'flake8-py3'
          linter_output_path: 'flake8-output.txt'
          commit_sha: ${{ steps.get_pr_tip.outputs.commit_sha }}
          regex: '^(?<filename>.*?):(?<lineNumber>\d+):(?<columnNumber>\d+): (?<errorCode>\w\d+) (?<errorDesc>.*)'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      #### Collect/upload stats
      - run: date -R >> ${{ runner.temp }}/${{ env.timingFile }}
      - name: Upload a Build Artifact
        uses: actions/upload-artifact@v2
        with:
          name: perfdata
          path: ${{ runner.temp }}/${{ env.artifactsDir }}
          if-no-files-found: error
      ##########################
        
  process:
    name: Process Perf Data
    runs-on: ubuntu-latest
    needs: [flake8-py3]
    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: 3.x
          architecture: x64
      - uses: actions/checkout@v2
        with:
          repository: pjquirk/runnerperf
          path: runnerperf
      - uses: actions/checkout@v2
        with:
          repository: pjquirk/iostat-tool
          path: runnerperf/iostat-tool
      - name: Download a Build Artifact
        uses: actions/download-artifact@v2  
        with:
          name: perfdata
          path: runnerperf/data
      - name: Prereqs
        run: sudo apt -y install datamash  
      - name: Process stats
        run: |
          cd runnerperf
          (cd iostat-tool && python setup.py develop)
          ls -l data
          script/dumpcsv.sh data output
          script/aggregate.sh output ${{ github.repository }}
      - name: Upload a Build Artifact
        uses: actions/upload-artifact@v2
        with:
          name: summary-perfdata
          path: runnerperf/output/summary.csv
          if-no-files-found: error
